#!/usr/bin/env python


from __future__ import division

# Standard python modules
import argparse
import emcee
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.stats import poisson
import sys

try:
    import corner
except ImportError:
    print 'Corner not available. Do not attempt to make corner plots with this code.'

# Astropy imports
from astropy import units
from astropy.cosmology import Planck15, z_at_value

# Modules specific to this code
import sys
sys.path.append("./gw_event_gen")
from netsim import Network
import redshift_rates_tool as rt


################################################


# Inport many arguments
argp = argparse.ArgumentParser()

# Number of bins
argp.add_argument('-n', '--num-bins', default=3, type=int, help='Number of redshift bins')

# Manually set bin edges
argp.add_argument('--bin-edges', default=None, help='Set in the format\
     [z1,z2,z3,z4,etc.] without spaces. Assumed to be redshift values. Flag not valid for euclidean universes.')

# Counts to use
argp.add_argument('--bg-lambda', default=100, help='Injected mean of a poisson process (Lambda)\
    for background events. Overwritten by --bg-counts.')
argp.add_argument('-b', '--bg-counts', default=None, help='Number of background samples.\
    This is the exact number of samples that will be drawn. This number\
    WILL NOT be used as the mean of a poisson process.')
argp.add_argument('-f', '--fg-counts', default='[100,100,100]', help='Set in the format\
     [COUNT1,COUNT2,COUNT3,etc.] without spaces.')

# Supply foreground samples directly
argp.add_argument('-F', '--fg-samples', default=None, help='Filename of all foreground\
    samples printed to a text file.')

# Generate samples with eventgen
argp.add_argument('-G', '--generate-fg', action='store_true', help='Generate events directly\
    with eventgen.')
argp.add_argument('-T', '--total-fg', default=None, \
    help='Total number of foreground samples to generate. This is the exact number of samples that will\
    be drawn. This number WILL NOT be used as the mean of a poisson process.')
argp.add_argument('-R', '--injected-rate', default=None, \
    help='Set the overall rate instead of the overall number of foreground samples. Units Gpc^-3*yr^-1.\
    Setting this triggers sample generation from a poisson process.')

# Define the universe
argp.add_argument('--universe', default='euclidean', help='Set the universe type to either euclidean \
    or lambdacdm.')

# Only optimally oriented binaries
argp.add_argument('-O', '--optimal', action='store_true', help='Only use optimally-oriented binaries.')

# Vary mass
argp.add_argument('-M', '--mass-distr', default='fixed_source', help='Set the binary masses to one \
    of the following: fixed_source, fixed_detector, variable.')

# Detection time
argp.add_argument('-y', '--time', default=1, help='Detection time in <VT> computation.')

# Define threshold SNR of search
argp.add_argument('-t', '--threshold-snr', default=3.5, help='Threshold SNR of search.')

# Define a minimum SNR
argp.add_argument('-m', '--min-snr', default=None, help='Minimum SNR for an astrophysical signal. \
    This can be larger than the threshold SNR.')

# Define a maximum redshift
argp.add_argument('-s', '--min-z', default=0, help='Minimum redshift considered.')

# Define a maximum redshift
argp.add_argument('-z', '--max-z', default=None, help='Maximum redshift extent considered.')

# Define a maximum distance (for Euclidean case)
argp.add_argument('--max-dist', default=None, help='Maximum distance considered (in Mpc).')
argp.add_argument('--min-dist', default=0, help='Minimum distance considered (in Mpc).')

# Logarithmically space redshift bins
argp.add_argument('-lb', '--log-bins', action='store_true', help='Logarithmically space redshift bins.\
    Default is linear spacing.')

# Min Lambda
argp.add_argument('--minlambda', default=5, help='Place a lower limit on possible Lambda values.')

# Max Lambda
argp.add_argument('--maxlambda', default=1000, help='Place an upper limit on possible Lambda values.')

# Sample uniform prior
argp.add_argument('-u', '--turn-prior-off', action='store_true', help='Set log prior to zero.')

# Output filename
argp.add_argument('-o', '--filename', default='temp.csv', help='File to store posterior samples.')

# Supply a random seed
argp.add_argument('-rs', '--randomseed', default=None, help='Supply a random seed for consistent results')


args = argp.parse_args()
################################################

# Random Seed
if args.randomseed is not None:
    rs = int(args.randomseed)
    rstate = np.random.RandomState(rs)
    np.random.seed(rs)
else:
    rstate = np.random.RandomState()
    np.random.seed()
    rs = None


# Store run parameters
num_bins = args.num_bins
snr_thresh = args.threshold_snr

# Set a network
network = Network()
mass1, mass2 = 10, 10  # Make this an option FIXME
if mass1 == mass2:
    equal_mass = True
else:
    equal_mass = False

mass_min, mass_max = 3, 45  # Make this an option FIXME
ifo = 'H1'
network.add_psd('H1')


# Convert minimum and maximum distance to redshifts
#dist_to_z = lambda dist: z_at_value(Planck15.luminosity_distance, dist * units.Mpc)

def dist_to_z(dist):
    return z_at_value(Planck15.luminosity_distance, dist * units.Mpc)

def z_to_dist(z):
    if z == 0:
        return 0
    else:
        return Planck15.luminosity_distance(z)

# Set the maximum distance, based on SNR, if not already provided
if args.min_snr != None:
    min_snr_astro = max(snr_thresh, args.min_snr)
else:
    min_snr_astro = snr_thresh

# Set bin edges
if args.universe == 'euclidean':
    # Set the max distance
    max_dist = args.max_dist
    if max_dist is None:
        max_dist = network.horizon(mass1=mass1, mass2=mass2,
            snr_threshold=float(min_snr_astro), fmin=10, fmax=2048)["H1"]  # Mpc
    else:
        max_dist = float(max_dist)

    # Set the minimum distance
    if args.min_dist == 0:
        min_dist = 0
    else:
        min_dist = float(args.min_dist)


    # Set bin edges
    if args.log_bins:
        bin_edges = np.logspace(max(-2, np.log10(min_dist)), np.log10(max_dist), num_bins+1)
    else:
        bin_edges = np.linspace(min_dist, max_dist, num_bins+1)

elif args.universe == 'lambdacdm':
    # Determine maximum possible z    
    if args.mass_distr == 'variable':
        max_z = rt.various_mass_horizon(snr_thresh)
    elif args.mass_distr == 'fixed_source' or args.mass_distr == 'fixed_detector':
        max_z = network.redshift_horizon(mass1=mass1, mass2=mass2, 
            snr_threshold=float(min_snr_astro), mass_distr=args.mass_distr)['H1']

    # Split into bins
    if args.min_z == 0:
        min_z = 0
    else:
        min_z = float(args.min_z)

    # If a maximum redshift was manually provided, use the more stringent of the two restrictions
    if args.max_z != None:
        max_z = min(float(args.max_z), max_z)

    # Set bin edges
    if args.bin_edges != None:
        bin_edges = [float(i) for i in args.bin_edges[1:-1].split(',')]
    elif args.log_bins:
        bin_edges = np.logspace(max(-2, np.log10(min_z)), np.log10(max_z), num_bins+1)
    else:
        bin_edges = np.linspace(min_z, max_z, num_bins+1)

else:
    raise ValueError('Invalid universe type.')

print bin_edges

# Set up sample collector object
collector = rt.SampleCollector(snr_thresh, bin_edges, 
    mass_distr=args.mass_distr, optimal=args.optimal, universe=args.universe,
    equal_mass=equal_mass, mass1=mass1, mass2=mass2, rs=rs)


# Compute total VT based on a single redshift bin spanning the entire redshfit range considered
total_bin = rt.RedshiftBin(z_low=bin_edges[0], z_high=bin_edges[-1],
    snr_thresh=snr_thresh, optimal=args.optimal, 
    mass_distr=args.mass_distr, mass1=mass1, mass2=mass2, 
    universe=args.universe, z_horiz=collector.z_horiz, 
    equal_mass=collector.equal_mass, rs=rs)
total_VT = total_bin.compute_VT(time=float(args.time))
print 'Total VT: %.2f Gpc^3 yr' % total_VT


# Set number of foreground samples, if appropriate
if args.total_fg != None:
    total_fg = int(float(args.total_fg)) 
elif args.injected_rate != None:
    # Find total fg counts based on total VT
    true_fg_lambda = float(args.injected_rate) * total_VT
    total_fg = poisson.rvs(true_fg_lambda)
else:
    # FIXME: set total fg based on either counts or samples provided
    pass

# If bg_counts is provided, generate EXACTLY this number of events
if args.bg_counts:
    bg_counts = int(float(args.bg_counts))

# If not, then use the provided bg_lambda to generate a number
# from a poisson process
elif args.bg_lambda:
    bg_counts = poisson.rvs(float(args.bg_lambda))

else:
    raise ValueError('Must set either bg_counts or bg_lambda.')

# Generate background samples
print 'Generating background samples (this can take a while)'
collector.assign_background_samples(bg_counts=bg_counts)


# Generate foreground samples
if args.generate_fg:
    print 'Starting to generate events (this can take a while)'
    if total_fg == 0:
        collector.assign_foreground_samples(fg_counts=0)
        true_values = np.zeros(num_bins+1)
        true_values[0] = bg_counts
    elif args.universe == 'euclidean':
        events = rt.generate_uniform_euclidean(dist_high=bin_edges[-1],
            optimal=args.optimal, mass_distr=args.mass_distr, mass1=mass1,
            mass2=mass2, snr_thresh=snr_thresh, num_events=total_fg,
            equal_mass=equal_mass, rs=rs)
        print 'Done generating events'

        if args.mass_distr == 'variable':
            collector.assign_foreground_samples(fg_samples=events)
        else:
            collector.assign_foreground_samples(fg_samples=events['snr'])

        true_values = [bg_counts]
        # Store true values for each bin
        for zbin in collector.redshift_bins:
            true_values.append(len(np.where(
                (events['distance'] < zbin.z_high) & (events['distance'] > zbin.z_low))[0]))

    else:
        events = rt.generate_comoving(z_low=bin_edges[0], 
            z_high=bin_edges[-1], optimal=args.optimal,
            mass_distr=args.mass_distr, mass1=mass1, mass2=mass2, 
            snr_thresh=snr_thresh, num_events=total_fg, equal_mass=equal_mass, rs=rs)
        print 'Done generating events'


        if args.mass_distr == 'variable':
            collector.assign_foreground_samples(fg_samples=events)
        else:
            collector.assign_foreground_samples(fg_samples=events['snr'])    

        true_values = [bg_counts]
        # Store true values for each bin
        for zbin in collector.redshift_bins:
            true_values.append(len(np.where((events['z'] < zbin.z_high) & (events['z'] > zbin.z_low))[0]))

# Set events based on provided counts
elif not args.fg_samples:
    bin_counts = [int(float(i)) for i in args.fg_counts[1:-1].split(',')]

    # If all entries in bin_counts are zero
    if np.count_nonzero(bin_counts) == 0:
        collector.assign_foreground_samples(fg_counts=0)
    else:
        collector.assign_foreground_samples(fg_counts=bin_counts)
    true_values = []
else:
    collector.assign_foreground_samples(fg_samples=np.loadtxt(args.fg_samples))
    true_values = []

print 'True Values: %s' % true_values 


# Compute likelihood statistics
collector.compute_likelihood_statistics()

# Prepare for MCMC
ndim = 1 + num_bins
nwalkers = 4 * ndim # FIXME check this a bit more
nburn = 1500

minlambda = float(args.minlambda)
maxlambda = float(args.maxlambda)

if maxlambda != np.inf:
    pos_init = np.random.uniform(low=minlambda, high=maxlambda, size=(nwalkers, ndim))
else:
    #pos_init = (len(collector.samples) / ndim) + np.random.randn(nwalkers, ndim)
    pos_init = np.repeat([true_values], nwalkers, axis=0)

sampler = emcee.EnsembleSampler(nwalkers, ndim, collector.lnprob, a=5, 
    args=[args.turn_prior_off, minlambda, maxlambda]) #, turn_like_off, prior_cut_off])
sampler.random_state = rstate.get_state()

# Perform MCMC
sampler.run_mcmc(pos_init, 15000)
post_samples = sampler.chain[:, nburn:, :].reshape((-1, ndim))



print 'MCMC Complete'

# Make labels of only bins
labels = ["Background"]
for i in range(len(collector.redshift_bins)):
    labels.append('Bin %i' % (i+1))

# Compute <VT> for each bin. Units: Gpc^3 yr
VT_arr = np.array([zbin.compute_VT(time=float(args.time)) \
    for zbin in collector.redshift_bins])
print 'VT_arr: %s' % VT_arr

# Divide each Lambda posterior by <VT> to get rate posteriors
post_samples = np.append(post_samples, post_samples[:,1:] / VT_arr, axis=1)

# Add rates to labels
for i in range(len(collector.redshift_bins)):
    labels.append('Rate %i' % (i+1))

# Store samples to data frame
df = pd.DataFrame(data=post_samples, columns=labels)
df.to_csv(args.filename, index_label=False)

# Expected rate
try:
    print 'Total FG:', total_fg
    print 'Total VT:', total_VT
    print 'Total R:', total_fg/total_VT
except NameError:
    pass

# Compute CDF of each posterior distribution
if num_bins == 1:
    try:
        # Background
        true_bg_lambda = float(args.bg_lambda)
        cdf_bg = rt.compute_cdf(df['Background'].values)
        bg_percentile = cdf_bg(true_bg_lambda)
        
        print 'The true background Lambda, %.2f, is recovered at the %.3f per cent level.' % (true_bg_lambda, 100*bg_percentile)

        # Foreground
        cdf_fg = rt.compute_cdf(df['Bin 1'].values)
        fg_percentile = cdf_bg(true_fg_lambda)
        
        print 'The true foreground Lambda, %.2f, is recovered at the %.3f per cent level.' % (true_fg_lambda, 100*fg_percentile)


        

    except ValueError:
        print 'This set of parameters is not configured for a standard test.'



# FIXME generalize for multiple bins





